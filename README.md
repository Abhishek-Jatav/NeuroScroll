
---

# ğŸ‘ï¸ JustBlink â€“ AI Vision Based Document Control System

> Control documents using your eyes.
> Real-time blink detection powered by AI + WebSocket + MediaPipe.

---

## ğŸš€ Overview

JustBlink (NeuroScroll) is a real-time human-computer interaction system that allows users to control documents using eye gestures.

The system:

* ğŸ¥ Captures live video
* ğŸ§  Extracts facial landmarks using MediaPipe
* ğŸ“Š Calculates Eye Aspect Ratio (EAR)
* ğŸ” Detects blink patterns using a state machine
* ğŸ“„ Scrolls a document in real time

---

## ğŸ—ï¸ System Architecture

Frontend (Next.js)
â†“
MediaPipe FaceMesh
â†“
WebSocket (Live Streaming)
â†“
FastAPI Backend
â†“
EAR Calculation
â†“
Blink State Machine
â†“
Gesture Response

---

## âœ¨ Features

### ğŸ‘ï¸ Gesture Controls

* ğŸ‘ Single Blink â†’ Scroll Down
* ğŸ‘ğŸ‘ Long Blink â†’ Scroll Up
* âš¡ Double Blink â†’ Click Action

### ğŸ§  Intelligent Detection

* Real-time EAR calculation
* Adaptive threshold calibration
* Blink state machine logic
* Noise-resistant detection

### ğŸ¨ Visual System Interface

* Live camera feed
* Green facial mesh overlay
* Real-time AI analysis simulation
* PDF-style document panel

---

## ğŸ› ï¸ Tech Stack

### Frontend

* Next.js (App Router)
* MediaPipe FaceMesh
* WebSocket API
* React

### Backend

* FastAPI
* Uvicorn
* NumPy
* MongoDB
* Python-dotenv

---

## ğŸ“‚ Project Structure

```
NeuroScroll/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ ear_calculator.py
â”‚   â”‚   â”œâ”€â”€ state_machine.py
â”‚   â”‚   â””â”€â”€ gesture_engine.py
â”‚   â”‚
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â””â”€â”€ websocket.py
â”‚   â”‚
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ VisionSystem.jsx
â”‚   â”‚   â”‚   â””â”€â”€ InstructionPDF.jsx
â”‚   â”‚   â””â”€â”€ page.tsx
â”‚
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation Guide

### ğŸ”¹ Backend Setup

```bash
cd backend
python -m venv venv
venv\Scripts\activate   # Windows
pip install -r requirements.txt
```

Run server:

```bash
uvicorn main:app --reload
```

Backend runs at:

```
http://localhost:8000
```

---

### ğŸ”¹ Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

Frontend runs at:

```
http://localhost:3000
```

---

## ğŸ­ Production Build

### Frontend

```bash
npm run build
npm start
```

### Backend

```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 2
```

---

## ğŸ§ª How It Works

### ğŸ‘ï¸ Eye Aspect Ratio (EAR)

EAR measures vertical eye openness:

```
EAR = (A + B) / (2C)
```

Where:

* A & B â†’ Vertical distances
* C â†’ Horizontal distance

Lower EAR â†’ Eye closed
Higher EAR â†’ Eye open

---

### ğŸ§  Blink Detection Logic

The system uses a finite state machine:

* Detect eye close
* Measure duration
* Classify blink type
* Apply cooldown window

---

## ğŸ¯ Demo Flow

1. Open system
2. Allow camera access
3. Calibration runs for 3 seconds
4. Blink to control document

---

## ğŸ”¥ Future Improvements

* ğŸ¯ Head movement cursor control
* ğŸ“Š Live EAR graph overlay
* ğŸ§  ML-based gesture model
* ğŸ“± Chrome Extension version
* ğŸ–¥ï¸ Desktop (Electron) app
* â˜ï¸ SaaS deployment

---

## ğŸ‘¨â€ğŸ’» Author

**Abhishek Jatav**
B.Tech â€“ Delhi Technological University

ğŸ”— LinkedIn:
[https://www.linkedin.com/in/abhishek-jatav-067946261](https://www.linkedin.com/in/abhishek-jatav-067946261)

ğŸŒ Portfolio:
[https://nexabuild-abhishek-jatav.netlify.app/](https://nexabuild-abhishek-jatav.netlify.app/)

---

## ğŸ“œ License

This project is for research and educational purposes.

---

# ğŸŒŸ JustBlink (NeuroScroll)

AI meets Accessibility.
Hands-free. Real-time. Intelligent.

---